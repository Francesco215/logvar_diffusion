# A Generalized Diffusion Model Training Framework

Let’s make score-based diffusion modeling more rigorous.

Suppose we have a dataset made of a single sample $x_0$, and we add noise to this sample as follows:

$$
\tilde x = x_0 + \sigma \cdot \epsilon
$$

This implies that the probability distribution is:

$$
p(x) = \mathcal{N}(x \mid x_0, \sigma^2)
$$

**But** what if $x_0$ is itself sampled from a small Gaussian? After all, most VAEs encode images using non-isotropic Gaussians and then the diffusion process adds noise on top. In this case:

$$
\tilde x = x_\textrm{vae} + \sigma_{\text{vae}} \cdot \epsilon + \sigma_{\text{diff}} \cdot \epsilon
$$

which gives:

$$
p(x) = \mathcal{N}\left(x \mid x_0, \sigma_{\text{VAE}}^2 + \sigma_{\text{diff}}^2 \right)
$$

You might think these two processes need separate treatments, but I’ll show you how to hit two pigeons with one stone.

From now on, we’ll consider the case where we sampe $\tilde x \sim p(x)$:

$$
\tilde x = x_0 + \sigma \cdot \epsilon
$$

and allow $\sigma$ to be non-isotropic.


## The Loss Function: From First Principles

How do you choose the loss function? You don’t — nature does it for you.

Given a data point $x$ and known noise level $\sigma^2$, we want to estimate the original distribution of $x_0$. That is, we aim to learn two functions $\mu_\theta(\tilde x)$, $\sigma_\phi(\tilde x)$ such that:

$$
q(x \mid \tilde x) = \mathcal{N}(x \mid \mu_\theta, \sigma_\phi^2)
$$

We then minimize the expected negative log-likelihood:

$$
L = \mathbb{E}_{\tilde x \sim p(x)}\left[-\log q(x \mid \tilde x)\right]
$$

Which decomposes into:

$$
L = \mathrm{KL}(p \| q) + S(p)
$$

Carrying out the KL divergence calculation, assuming known noise level $\sigma$, we get:

$$
L = \frac{1}{2} \left[\log \sigma_\phi^2 + \frac{\sigma^2 + (\mu_\theta - x_0)^2}{\sigma_\phi^2} + \log(2\pi) \right]
$$


### Properties of the Loss

At the minimum, the optimal value of $\sigma_\phi$ satisfies:

$$
\frac{\partial L}{\partial \sigma_\phi} = 0 \quad \Rightarrow \quad \sigma_\phi^2 = \sigma^2 + (\mu_\theta - x_0)^2
$$

So the learned variance converges to the sum of the added noise and the model’s squared prediction error — an adaptive uncertainty estimate.

Also, the gradient with respect to $\mu_\theta$ is:

$$
\frac{\partial L}{\partial \mu_\theta} = \frac{\mu_\theta - x_0}{\sigma_\phi^2}
$$

This resembles the gradient of the MSE loss, but weighted by the expected prediction error $\sigma_\phi^2$ (As it should!).


## The Score Function

The core objective of score-based diffusion models is to estimate the **score function**, defined as:

$$
s(x) = \nabla_x \log p(x)
$$

However, since $p(x)$ is typically unknown, what we do instead is simulate samples of the form:

$$
\tilde x = x_0 + \sigma \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)
$$

Here, $x_0$ is a clean data sample, and $x$ is a noisy version. Under this assumption, the conditional distribution of $x \mid x_0$ is:

$$
p(x \mid x_0) = \mathcal{N}(x \mid x_0, \sigma^2)
$$

Since $x$ is generated by adding Gaussian noise to a fixed $x_0$, we can compute the score of this conditional distribution analytically:

$$
\nabla_x \log p(x \mid x_0) = -\frac{x - x_0}{\sigma^2}
$$

So a natural estimator of the **true score** of $p(x)$ is:

$$
s(x|x_0) \approx -\frac{x - x_0}{\sigma^2}
$$

This is the formulation that is used in score matching, after all, the models use only predict $x_0(\tilde x)$, so it's "natural" to use this score function.

### The Problem with This Formulation

While the standard derivation is elegant, it has several practical limitations:
1. **Wrong $\sigma$**: It assumes that the uncertanty of the prediction is equal to $\sigma$ which is generally wrong.

2. **Numerical instability**: As $\sigma \to 0$, the denominator $\sigma^2$ becomes very small, making the score explode in magnitude.

3. **Uncertainty mismatch**: In practice, $x_0$ may itself be drawn from a distribution, such as the decoder of a VAE where:

   $$
   x_0 = x_\textrm{vae} + \sigma_\textrm{vae}\cdot \epsilon
   $$

   In such cases, treating $x_0$ as a point estimate and using its mean in the numerator is an oversimplification.

---

### A Better Score Function

We actually can estimate the score with $q$! After all, $q$ is the best approximation of $p$

$$
s(x|\tilde x) = \nabla_x \log q(x|\tilde x) 
$$

Let's recall that $q(x|\tilde x) = \mathcal N(x, \mu_\theta(\tilde x), \sigma^2_\theta(\tilde x))$

And in the end we get this!

$$
\nabla_x \log q(x|\tilde x) = -\frac{x - \mu_\theta(\tilde x)}{\sigma_\phi^2(\tilde x)}
$$

This form:

- Naturally reduces to the standard formula when $\sigma_\phi \to 0$
- Remains stable for small $\sigma$
- Properly incorporates **epistemic uncertainty** (via $\sigma_\phi$) from the learned model

## Preconditioning
When it comes with writing an implementation one has to be careful, Neural networks don't like really large and really small numbers.

Training a model to predict directly $\mu_\theta$ and $\sigma_\phi$ is far from ideal. For this reason we have to re-parametrize it.

$$
\begin{cases}
\mu_\theta(x, \sigma, \sigma_\phi) = c_\textrm{skip}\cdot x + c_\textrm{out}\cdot F_\theta(c_\textrm{in}\cdot x,c_\textrm{noise})\\
\sigma_\phi(x,\sigma) = \sigma\cdot\exp\left[\frac 12 G_\phi(c_\textrm{in}\cdot x, c_\textrm{noise})\right]
\end{cases}
$$
Where $(F_\theta,G_\phi)$ is the actual neural network output, and 
$$
\begin{cases}
c_\textrm{skip}(\sigma) = \sigma_\textrm{data}/(\sigma^2 + \sigma_\textrm{data}^2)\\
c_\textrm{out}(\sigma) = \sigma\cdot \sigma_\textrm{data}/\sqrt{\sigma^2 + \sigma_\textrm{data}^2}\\
c_\textrm{in}(\sigma) = 1/\sqrt{\sigma^2 + \sigma_\textrm{data}^2}\\
c_\textrm{noise}=\frac 14 \log\sigma
\end{cases}
$$

### Simplified Loss
$$
L = G_\phi +e^{-G_\phi}\left(1 + \frac{(\mu_\theta-x_0)^2}{\sigma^2}\right) + \log(2\pi\sigma^2)
$$





# Solving the ODE

With the training complete, our model provides the functions $\mu_\theta(x, \sigma)$ and $\sigma_\phi(x, \sigma)$, which estimate the mean and variance of the clean data distribution given a noisy input $x$ at noise level $\sigma$. The generative process reverses the diffusion, starting from pure noise and progressively denoising it to produce a clean sample. This reverse process is defined by a probability flow Ordinary Differential Equation (ODE). As derived in the next section, the ODE for our framework is:

$$\frac{d\mathbf{x}}{d\sigma} = \frac{\sigma(x - \mu_\theta(x, \sigma))}{\sigma_\phi^2(x, \sigma)}$$

To generate a sample, we start with a draw from a simple prior, $x_T \sim \mathcal{N}(0, \sigma_{max}^2 I)$, and integrate this ODE backward from a high noise level $\sigma_{max}$ down to $\sigma_{min} \approx 0$. This is done numerically by discretizing the noise schedule into a sequence of steps $(\sigma_N, \sigma_{N-1}, \dots, \sigma_0)$ and applying a standard ODE solver like the Euler method. A single step of the Euler integrator from $\sigma_i$ to $\sigma_{i-1}$ is given by:

$$x_{i-1} = x_i + (\sigma_{i-1} - \sigma_i) \cdot \frac{d\mathbf{x}}{d\sigma}\bigg|_{x=x_i, \sigma=\sigma_i} = x_i - (\sigma_i - \sigma_{i-1}) \cdot \frac{\sigma_i(x_i - \mu_\theta(x_i, \sigma_i))}{\sigma_\phi^2(x_i, \sigma_i)}$$

This formulation elegantly incorporates the model's learned uncertainty into the sampling process. The magnitude of each denoising step is inversely proportional to $\sigma_\phi^2$, the model's confidence in its prediction. When the model is certain (low $\sigma_\phi^2$), it takes a large, confident step toward the predicted clean data $\mu_\theta$. When it is uncertain (high $\sigma_\phi^2$), it proceeds more cautiously, leading to a more stable and robust generation process. ✨

---
## Derivation: From Forward to Reverse Process

The entire framework is built on a pair of processes: a **forward process** that systematically adds noise to data, and a **reverse process** that learns to undo the noise.

### The Forward Process
The forward process describes how a clean data sample $x_0$ is gradually corrupted into pure noise. This is modeled by a **Stochastic Differential Equation (SDE)**. The setup $\tilde x = x_0 + \sigma \cdot \epsilon$ corresponds to a **Variance Exploding (VE) SDE**:

$$d\mathbf{x} = \sqrt{\frac{d[\sigma(t)^2]}{dt}} d\mathbf{w}$$

Here, $\sigma(t)$ is a noise schedule function, and $d\mathbf{w}$ represents Gaussian noise. This equation describes continuously adding noise to the data such that at any "time" $t$, the noisy sample's distribution is $p(x_t|x_0) = \mathcal{N}(x_t \mid x_0, \sigma(t)^2 I)$.

### The Reverse Process
The reverse process is also a diffusion process, but running backward in time. For sampling, we use its deterministic version, the **probability flow ODE**:

$$d\mathbf{x} = \left[ \mathbf{f}(\mathbf{x},t) - \frac{1}{2} g(t)^2 \nabla_{\mathbf{x}} \log p_t(\mathbf{x}) \right] dt$$

For our VE SDE, the drift $\mathbf{f}(\mathbf{x}, t)$ is zero and $g(t)^2 = \frac{d[\sigma(t)^2]}{dt}$. Plugging these in and using the score function $s_\theta(x, t) = \nabla_{\mathbf{x}} \log p_t(\mathbf{x})$:

$$d\mathbf{x} = -\frac{1}{2} \left( \frac{d[\sigma(t)^2]}{dt} \right) s_\theta(x, t) dt = -\sigma \frac{d\sigma}{dt} s_\theta(x, t) dt$$

To get the final ODE, we change the variable of integration from time $t$ to the noise level $\sigma$, which yields:

$$\frac{d\mathbf{x}}{d\sigma} = -\sigma \cdot s_\theta(x, \sigma)$$

Finally, we substitute our "better score function," $s_\theta(x, \sigma) = -\frac{x - \mu_\theta(x, \sigma)}{\sigma_\phi^2(x, \sigma)}$:

$$\frac{d\mathbf{x}}{d\sigma} = -\sigma \left( -\frac{x - \mu_\theta(x, \sigma)}{\sigma_\phi^2(x, \sigma)} \right) = \frac{\sigma(x - \mu_\theta(x, \sigma))}{\sigma_\phi^2(x, \sigma)}$$

This is the ODE we solve to generate new data.

---
## Appendix: A Note on the Derivative

You might wonder why the ODE derivative is with respect to `σ` and not `σ_φ`. The reason is that `σ` and `σ_φ` play fundamentally different roles:

* **`σ` (Sigma)** is the **independent variable** that defines the stage of the diffusion process. It's a predefined parameter that tells us the noise level. The generative process is all about evolving the sample `x` by changing `σ` from `σ_max` down to `0`.

* **`σ_φ` (Sigma-phi)** is a **dependent variable**. It is the *output* of our neural network, which depends on the current sample `x` and the current noise level `σ`. It represents the model's learned uncertainty about its prediction at that specific stage.

Therefore, the derivative `dx/dσ` correctly describes the path of the sample `x(σ)` as the noise level `σ` changes.
